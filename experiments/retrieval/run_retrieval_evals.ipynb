{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 07:46:23.369297: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-17 07:46:23.372905: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-17 07:46:23.425822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 07:46:24.576836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from target_benchmark.evaluators import TARGET, get_task_names\n",
    "target_fetaqa = TARGET((\"Table Retrieval Task\", \"fetaqa\"))\n",
    "target_ottqa = TARGET((\"Table Retrieval Task\", \"ottqa\"))\n",
    "target_tabfact = TARGET((\"Table Retrieval Task\", \"tabfact\"))\n",
    "target_spider = TARGET((\"Table Retrieval Task\", \"spider-test\"))\n",
    "target_bird = TARGET((\"Table Retrieval Task\", \"bird-validation\"))\n",
    "target_infiagentda = TARGET((\"Table Retrieval Task\", \"infiagentda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ks = [1, 5, 10, 25, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval_for_top_ks(retriever, retriever_name: str, top_ks: list[int], target: TARGET, dataset_name: str, split: str):\n",
    "    results = []\n",
    "    for top_k in top_ks:\n",
    "        results.append(target.run(retriever=retriever, split=split, batch_size=100, top_k=top_k, retrieval_results_file=f\"./{retriever_name}/{dataset_name}_{top_k}.jsonl\"))\n",
    "    print(results)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_benchmark.retrievers import LlamaIndexRetriever\n",
    "llamaindex_retriever = LlamaIndexRetriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetaqa Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaindex_results_fetaqa_test = run_eval_for_top_ks(llamaindex_retriever, \"llamaindex\",top_ks, target_fetaqa, \"fetaqa\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.2381427858212681, precision=None, recall=None, retrieval_time=405.29509, avg_retrieval_time=0.20234), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=152.35639, avg_embedding_creation_duration=0.07606, embedding_size=8.53197, avg_embedding_size=0.00426))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.37993010484273587, precision=None, recall=None, retrieval_time=429.66376, avg_retrieval_time=0.21451), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=20.32173, avg_embedding_creation_duration=0.01015, embedding_size=0.0, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=10, accuracy=0.436345481777334, precision=None, recall=None, retrieval_time=412.36555, avg_retrieval_time=0.20587), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=20.23989, avg_embedding_creation_duration=0.0101, embedding_size=0.0, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.545681477783325, precision=None, recall=None, retrieval_time=413.68584, avg_retrieval_time=0.20653), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=20.08907, avg_embedding_creation_duration=0.01003, embedding_size=0.0041, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.6230654018971543, precision=None, recall=None, retrieval_time=418.37355, avg_retrieval_time=0.20887), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=20.56766, avg_embedding_creation_duration=0.01027, embedding_size=0.0041, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamaindex_results_fetaqa_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTTQA bm25 with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_benchmark.retrievers import OTTQARetriever\n",
    "bm25_with_title = OTTQARetriever(encoding=\"bm25\", withtitle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 47.29it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.98it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:01<00:00, 1448.22it/s]\n",
      "1it [00:00, 46.31it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.00it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:01<00:00, 1229.51it/s]\n",
      "1it [00:00, 63.06it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.92it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:02<00:00, 902.35it/s]\n",
      "1it [00:00, 62.10it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.43it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:02<00:00, 708.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.02895656515227159, precision=None, recall=None, retrieval_time=1.30831, avg_retrieval_time=0.00065), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.52735, avg_embedding_creation_duration=0.00226, embedding_size=0.00819, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.06090863704443335, precision=None, recall=None, retrieval_time=1.41867, avg_retrieval_time=0.00071), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.90114, avg_embedding_creation_duration=0.00245, embedding_size=0.0041, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.13030454318522217, precision=None, recall=None, retrieval_time=1.59272, avg_retrieval_time=0.0008), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.5114, avg_embedding_creation_duration=0.00225, embedding_size=0.00819, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.18172740888667, precision=None, recall=None, retrieval_time=1.78035, avg_retrieval_time=0.00089), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.55346, avg_embedding_creation_duration=0.00227, embedding_size=0.0041, avg_embedding_size=0.0))}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fetaqa\n",
    "bm25_with_title_results_fetaqa_test = run_eval_for_top_ks(bm25_with_title, \"bm25_with_title\",top_ks, target_fetaqa, \"fetaqa\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.02895656515227159, precision=None, recall=None, retrieval_time=1.30831, avg_retrieval_time=0.00065), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.52735, avg_embedding_creation_duration=0.00226, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.06090863704443335, precision=None, recall=None, retrieval_time=1.41867, avg_retrieval_time=0.00071), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.90114, avg_embedding_creation_duration=0.00245, embedding_size=0.0041, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.13030454318522217, precision=None, recall=None, retrieval_time=1.59272, avg_retrieval_time=0.0008), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.5114, avg_embedding_creation_duration=0.00225, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.18172740888667, precision=None, recall=None, retrieval_time=1.78035, avg_retrieval_time=0.00089), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.55346, avg_embedding_creation_duration=0.00227, embedding_size=0.0041, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_with_title_results_fetaqa_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 128.92it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.85it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:01<00:00, 1184.23it/s]\n",
      "1it [00:00, 246.27it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.24it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:02<00:00, 1020.87it/s]\n",
      "1it [00:00, 194.21it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.68it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:03<00:00, 675.35it/s]\n",
      "1it [00:00, 166.94it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.58it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:04<00:00, 488.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.7389340560072267, precision=None, recall=None, retrieval_time=1.77246, avg_retrieval_time=0.0008), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.6389, avg_embedding_creation_duration=0.00461, embedding_size=-0.70042, avg_embedding_size=-0.00089))}}, {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.9155374887082204, precision=None, recall=None, retrieval_time=1.91067, avg_retrieval_time=0.00086), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.57852, avg_embedding_creation_duration=0.00454, embedding_size=0.0041, avg_embedding_size=1e-05))}}, {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.971996386630533, precision=None, recall=None, retrieval_time=2.32853, avg_retrieval_time=0.00105), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.56682, avg_embedding_creation_duration=0.00452, embedding_size=0.0041, avg_embedding_size=1e-05))}}, {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.9778681120144534, precision=None, recall=None, retrieval_time=2.85658, avg_retrieval_time=0.00129), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.59817, avg_embedding_creation_duration=0.00456, embedding_size=0.0, avg_embedding_size=0.0))}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ottqa\n",
    "bm25_with_title_results_ottqa_val = run_eval_for_top_ks(bm25_with_title, \"bm25_with_title\",top_ks, target_ottqa, \"ottqa\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.7389340560072267, precision=None, recall=None, retrieval_time=1.77246, avg_retrieval_time=0.0008), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.6389, avg_embedding_creation_duration=0.00461, embedding_size=-0.70042, avg_embedding_size=-0.00089))}},\n",
       " {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.9155374887082204, precision=None, recall=None, retrieval_time=1.91067, avg_retrieval_time=0.00086), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.57852, avg_embedding_creation_duration=0.00454, embedding_size=0.0041, avg_embedding_size=1e-05))}},\n",
       " {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.971996386630533, precision=None, recall=None, retrieval_time=2.32853, avg_retrieval_time=0.00105), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.56682, avg_embedding_creation_duration=0.00452, embedding_size=0.0041, avg_embedding_size=1e-05))}},\n",
       " {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.9778681120144534, precision=None, recall=None, retrieval_time=2.85658, avg_retrieval_time=0.00129), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.59817, avg_embedding_creation_duration=0.00456, embedding_size=0.0, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_with_title_results_ottqa_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 77.45it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.75it/s]\n",
      "Retrieving Tables for tabfact...: 100%|██████████| 12779/12779 [00:08<00:00, 1424.77it/s]\n",
      "1it [00:00, 81.46it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.04it/s]\n",
      "Retrieving Tables for tabfact...: 100%|██████████| 12779/12779 [00:11<00:00, 1152.63it/s]\n",
      "1it [00:00, 77.29it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.63it/s]\n",
      "Retrieving Tables for tabfact...: 100%|██████████| 12779/12779 [00:17<00:00, 725.27it/s]\n",
      "1it [00:00, 77.52it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.32it/s]\n",
      "Retrieving Tables for tabfact...: 100%|██████████| 12779/12779 [00:25<00:00, 494.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.14719461616714924, precision=None, recall=None, retrieval_time=8.41716, avg_retrieval_time=0.00066), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.29053, avg_embedding_creation_duration=0.00253, embedding_size=0.49152, avg_embedding_size=0.00029))}}, {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.27341732529931917, precision=None, recall=None, retrieval_time=9.53659, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.24604, avg_embedding_creation_duration=0.00251, embedding_size=0.0041, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.4433836763440019, precision=None, recall=None, retrieval_time=11.7532, avg_retrieval_time=0.00092), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.28083, avg_embedding_creation_duration=0.00253, embedding_size=0.00819, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.536818217387902, precision=None, recall=None, retrieval_time=15.02465, avg_retrieval_time=0.00118), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.28207, avg_embedding_creation_duration=0.00253, embedding_size=0.0041, avg_embedding_size=0.0))}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tabfact\n",
    "bm25_with_title_results_tabfact_test = run_eval_for_top_ks(bm25_with_title, \"bm25_with_title\",top_ks, target_tabfact, \"tabfact\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.14719461616714924, precision=None, recall=None, retrieval_time=8.41716, avg_retrieval_time=0.00066), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.29053, avg_embedding_creation_duration=0.00253, embedding_size=0.49152, avg_embedding_size=0.00029))}},\n",
       " {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.27341732529931917, precision=None, recall=None, retrieval_time=9.53659, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.24604, avg_embedding_creation_duration=0.00251, embedding_size=0.0041, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.4433836763440019, precision=None, recall=None, retrieval_time=11.7532, avg_retrieval_time=0.00092), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.28083, avg_embedding_creation_duration=0.00253, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.536818217387902, precision=None, recall=None, retrieval_time=15.02465, avg_retrieval_time=0.00118), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.28207, avg_embedding_creation_duration=0.00253, embedding_size=0.0041, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_with_title_results_tabfact_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ede19288bb54f5dae1fce6e8807df28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 132 files:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 592.16it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 195.55it/s]\n",
      "Retrieving Tables for spider-test...: 100%|██████████| 2147/2147 [00:08<00:00, 240.04it/s]\n",
      "1it [00:00, 474.68it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.27it/s]\n",
      "Retrieving Tables for spider-test...: 100%|██████████| 2147/2147 [00:23<00:00, 91.09it/s] \n",
      "1it [00:00, 221.56it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.56it/s]\n",
      "Retrieving Tables for spider-test...: 100%|██████████| 2147/2147 [00:28<00:00, 75.70it/s] \n",
      "1it [00:00, 512.81it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 185.33it/s]\n",
      "Retrieving Tables for spider-test...: 100%|██████████| 2147/2147 [00:34<00:00, 62.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.6348393106660456, precision=None, recall=None, retrieval_time=1.82872, avg_retrieval_time=0.00085), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73522, avg_embedding_creation_duration=0.02075, embedding_size=-0.86016, avg_embedding_size=-0.00478))}}, {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.8304611085235212, precision=None, recall=None, retrieval_time=1.45708, avg_retrieval_time=0.00068), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.78847, avg_embedding_creation_duration=0.02105, embedding_size=0.0041, avg_embedding_size=2e-05))}}, {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.8737773637633908, precision=None, recall=None, retrieval_time=1.60808, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.75677, avg_embedding_creation_duration=0.02087, embedding_size=0.00819, avg_embedding_size=5e-05))}}, {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.8779692594317653, precision=None, recall=None, retrieval_time=1.7037, avg_retrieval_time=0.00079), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73507, avg_embedding_creation_duration=0.02075, embedding_size=0.0, avg_embedding_size=0.0))}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# spider\n",
    "bm25_with_title_results_spider_test = run_eval_for_top_ks(bm25_with_title, \"bm25_with_title\",top_ks, target_spider, \"spider\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.6348393106660456, precision=None, recall=None, retrieval_time=1.82872, avg_retrieval_time=0.00085), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73522, avg_embedding_creation_duration=0.02075, embedding_size=-0.86016, avg_embedding_size=-0.00478))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.8304611085235212, precision=None, recall=None, retrieval_time=1.45708, avg_retrieval_time=0.00068), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.78847, avg_embedding_creation_duration=0.02105, embedding_size=0.0041, avg_embedding_size=2e-05))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.8737773637633908, precision=None, recall=None, retrieval_time=1.60808, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.75677, avg_embedding_creation_duration=0.02087, embedding_size=0.00819, avg_embedding_size=5e-05))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.8779692594317653, precision=None, recall=None, retrieval_time=1.7037, avg_retrieval_time=0.00079), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73507, avg_embedding_creation_duration=0.02075, embedding_size=0.0, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_with_title_results_spider_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTTQA bm25 without Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_benchmark.retrievers import OTTQARetriever\n",
    "bm25_no_title = OTTQARetriever(encoding=\"bm25\", withtitle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 47.29it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.98it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:01<00:00, 1448.22it/s]\n",
      "1it [00:00, 46.31it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.00it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:01<00:00, 1229.51it/s]\n",
      "1it [00:00, 63.06it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.92it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:02<00:00, 902.35it/s]\n",
      "1it [00:00, 62.10it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.43it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:02<00:00, 708.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.02895656515227159, precision=None, recall=None, retrieval_time=1.30831, avg_retrieval_time=0.00065), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.52735, avg_embedding_creation_duration=0.00226, embedding_size=0.00819, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.06090863704443335, precision=None, recall=None, retrieval_time=1.41867, avg_retrieval_time=0.00071), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.90114, avg_embedding_creation_duration=0.00245, embedding_size=0.0041, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.13030454318522217, precision=None, recall=None, retrieval_time=1.59272, avg_retrieval_time=0.0008), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.5114, avg_embedding_creation_duration=0.00225, embedding_size=0.00819, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.18172740888667, precision=None, recall=None, retrieval_time=1.78035, avg_retrieval_time=0.00089), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.55346, avg_embedding_creation_duration=0.00227, embedding_size=0.0041, avg_embedding_size=0.0))}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fetaqa\n",
    "bm25_no_title_results_fetaqa_test = run_eval_for_top_ks(bm25_no_title, \"bm25_no_title\", top_ks, target_fetaqa, \"fetaqa\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.02895656515227159, precision=None, recall=None, retrieval_time=1.30831, avg_retrieval_time=0.00065), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.52735, avg_embedding_creation_duration=0.00226, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.06090863704443335, precision=None, recall=None, retrieval_time=1.41867, avg_retrieval_time=0.00071), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.90114, avg_embedding_creation_duration=0.00245, embedding_size=0.0041, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.13030454318522217, precision=None, recall=None, retrieval_time=1.59272, avg_retrieval_time=0.0008), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.5114, avg_embedding_creation_duration=0.00225, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.18172740888667, precision=None, recall=None, retrieval_time=1.78035, avg_retrieval_time=0.00089), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.55346, avg_embedding_creation_duration=0.00227, embedding_size=0.0041, avg_embedding_size=0.0))}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bm25_no_title_results_fetaqa_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ottqa\n",
    "bm25_no_title_results_ottqa_val = run_eval_for_top_ks(bm25_no_title, \"bm25_no_title\",top_ks, target_ottqa, \"ottqa\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_no_title_results_ottqa_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabfact\n",
    "bm25_no_title_results_tabfact_test = run_eval_for_top_ks(bm25_no_title, \"bm25_no_title\",top_ks, target_tabfact, \"tabfact\", \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_no_title_results_tabfact_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spider\n",
    "bm25_no_title_results_spider_test = run_eval_for_top_ks(bm25_no_title, \"bm25_no_title\",top_ks, target_spider, \"spider\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.6348393106660456, precision=None, recall=None, retrieval_time=1.82872, avg_retrieval_time=0.00085), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73522, avg_embedding_creation_duration=0.02075, embedding_size=-0.86016, avg_embedding_size=-0.00478))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.8304611085235212, precision=None, recall=None, retrieval_time=1.45708, avg_retrieval_time=0.00068), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.78847, avg_embedding_creation_duration=0.02105, embedding_size=0.0041, avg_embedding_size=2e-05))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.8737773637633908, precision=None, recall=None, retrieval_time=1.60808, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.75677, avg_embedding_creation_duration=0.02087, embedding_size=0.00819, avg_embedding_size=5e-05))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.8779692594317653, precision=None, recall=None, retrieval_time=1.7037, avg_retrieval_time=0.00079), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73507, avg_embedding_creation_duration=0.02075, embedding_size=0.0, avg_embedding_size=0.0))}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bm25_no_title_results_spider_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "target",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
