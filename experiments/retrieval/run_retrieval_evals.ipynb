{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 09:01:31.034113: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-17 09:01:31.037670: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-17 09:01:31.090959: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 09:01:32.199756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from target_benchmark.evaluators import TARGET, get_task_names\n",
    "target_fetaqa = TARGET((\"Table Retrieval Task\", \"fetaqa\"))\n",
    "target_ottqa = TARGET((\"Table Retrieval Task\", \"ottqa\"))\n",
    "target_tabfact = TARGET((\"Table Retrieval Task\", \"tabfact\"))\n",
    "target_spider = TARGET((\"Table Retrieval Task\", \"spider-test\"))\n",
    "target_bird = TARGET((\"Table Retrieval Task\", \"bird-validation\"))\n",
    "target_infiagentda = TARGET((\"Table Retrieval Task\", \"infiagentda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ks = [1, 5, 10, 25, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval_for_top_ks(retriever, retriever_name: str, top_ks: list[int], target: TARGET, dataset_name: str, split: str):\n",
    "    results = []\n",
    "    for top_k in top_ks:\n",
    "        results.append(target.run(retriever=retriever, split=split, batch_size=100, top_k=top_k, retrieval_results_file=f\"./{retriever_name}/{dataset_name}_{top_k}.jsonl\"))\n",
    "    print(results)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_benchmark.retrievers import LlamaIndexRetriever\n",
    "llamaindex_retriever = LlamaIndexRetriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetaqa Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaindex_results_fetaqa_test = run_eval_for_top_ks(llamaindex_retriever, \"llamaindex\",top_ks, target_fetaqa, \"fetaqa\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.2381427858212681, precision=None, recall=None, retrieval_time=405.29509, avg_retrieval_time=0.20234), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=152.35639, avg_embedding_creation_duration=0.07606, embedding_size=8.53197, avg_embedding_size=0.00426))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.37993010484273587, precision=None, recall=None, retrieval_time=429.66376, avg_retrieval_time=0.21451), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=20.32173, avg_embedding_creation_duration=0.01015, embedding_size=0.0, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=10, accuracy=0.436345481777334, precision=None, recall=None, retrieval_time=412.36555, avg_retrieval_time=0.20587), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=20.23989, avg_embedding_creation_duration=0.0101, embedding_size=0.0, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.545681477783325, precision=None, recall=None, retrieval_time=413.68584, avg_retrieval_time=0.20653), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=20.08907, avg_embedding_creation_duration=0.01003, embedding_size=0.0041, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.6230654018971543, precision=None, recall=None, retrieval_time=418.37355, avg_retrieval_time=0.20887), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=20.56766, avg_embedding_creation_duration=0.01027, embedding_size=0.0041, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamaindex_results_fetaqa_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTTQA bm25 with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_benchmark.retrievers import OTTQARetriever\n",
    "bm25_with_title = OTTQARetriever(encoding=\"bm25\", withtitle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetaqa\n",
    "bm25_with_title_results_fetaqa_test = run_eval_for_top_ks(bm25_with_title, \"bm25_with_title\",top_ks, target_fetaqa, \"fetaqa\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.02895656515227159, precision=None, recall=None, retrieval_time=1.35066, avg_retrieval_time=0.00067), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.71769, avg_embedding_creation_duration=0.00236, embedding_size=205.42669, avg_embedding_size=0.10256))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.06090863704443335, precision=None, recall=None, retrieval_time=1.44027, avg_retrieval_time=0.00072), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.32921, avg_embedding_creation_duration=0.00216, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=10, accuracy=0.08237643534697953, precision=None, recall=None, retrieval_time=1.47959, avg_retrieval_time=0.00074), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.33622, avg_embedding_creation_duration=0.00216, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.13030454318522217, precision=None, recall=None, retrieval_time=1.66203, avg_retrieval_time=0.00083), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.28548, avg_embedding_creation_duration=0.00214, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.18172740888667, precision=None, recall=None, retrieval_time=1.83835, avg_retrieval_time=0.00092), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.2709, avg_embedding_creation_duration=0.00213, embedding_size=0.0041, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_with_title_results_fetaqa_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 157.05it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.42it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:01<00:00, 1147.30it/s]\n",
      "1it [00:00, 151.92it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.93it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:02<00:00, 848.56it/s] \n",
      "1it [00:00, 153.89it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.67it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:02<00:00, 840.96it/s]\n",
      "1it [00:00, 140.02it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.44it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:03<00:00, 653.40it/s]\n",
      "1it [00:00, 125.50it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.54it/s]\n",
      "Retrieving Tables for ottqa...: 100%|██████████| 2214/2214 [00:04<00:00, 470.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.7389340560072267, precision=None, recall=None, retrieval_time=1.82809, avg_retrieval_time=0.00083), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.61114, avg_embedding_creation_duration=0.00458, embedding_size=0.42189, avg_embedding_size=0.00053))}}, {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.9155374887082204, precision=None, recall=None, retrieval_time=2.35379, avg_retrieval_time=0.00106), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.51366, avg_embedding_creation_duration=0.00445, embedding_size=0.0041, avg_embedding_size=1e-05))}}, {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=10, accuracy=0.9552845528455285, precision=None, recall=None, retrieval_time=2.14623, avg_retrieval_time=0.00097), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.56432, avg_embedding_creation_duration=0.00452, embedding_size=0.00819, avg_embedding_size=1e-05))}}, {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.971996386630533, precision=None, recall=None, retrieval_time=2.40749, avg_retrieval_time=0.00109), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.46983, avg_embedding_creation_duration=0.0044, embedding_size=0.0041, avg_embedding_size=1e-05))}}, {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.9778681120144534, precision=None, recall=None, retrieval_time=3.01085, avg_retrieval_time=0.00136), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.47604, avg_embedding_creation_duration=0.00441, embedding_size=0.0041, avg_embedding_size=1e-05))}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ottqa\n",
    "bm25_with_title_results_ottqa_val = run_eval_for_top_ks(bm25_with_title, \"bm25_with_title\",top_ks, target_ottqa, \"ottqa\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.7389340560072267, precision=None, recall=None, retrieval_time=1.82809, avg_retrieval_time=0.00083), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.61114, avg_embedding_creation_duration=0.00458, embedding_size=0.42189, avg_embedding_size=0.00053))}},\n",
       " {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.9155374887082204, precision=None, recall=None, retrieval_time=2.35379, avg_retrieval_time=0.00106), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.51366, avg_embedding_creation_duration=0.00445, embedding_size=0.0041, avg_embedding_size=1e-05))}},\n",
       " {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=10, accuracy=0.9552845528455285, precision=None, recall=None, retrieval_time=2.14623, avg_retrieval_time=0.00097), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.56432, avg_embedding_creation_duration=0.00452, embedding_size=0.00819, avg_embedding_size=1e-05))}},\n",
       " {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.971996386630533, precision=None, recall=None, retrieval_time=2.40749, avg_retrieval_time=0.00109), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.46983, avg_embedding_creation_duration=0.0044, embedding_size=0.0041, avg_embedding_size=1e-05))}},\n",
       " {'Table Retrieval Task': {'ottqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.9778681120144534, precision=None, recall=None, retrieval_time=3.01085, avg_retrieval_time=0.00136), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.47604, avg_embedding_creation_duration=0.00441, embedding_size=0.0041, avg_embedding_size=1e-05))}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_with_title_results_ottqa_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 64.79it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.89it/s]\n",
      "Retrieving Tables for tabfact...: 100%|██████████| 12779/12779 [00:09<00:00, 1404.07it/s]\n",
      "1it [00:00, 77.51it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.59it/s]\n",
      "Retrieving Tables for tabfact...: 100%|██████████| 12779/12779 [00:11<00:00, 1139.00it/s]\n",
      "1it [00:00, 74.30it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.08it/s]\n",
      "Retrieving Tables for tabfact...:  27%|██▋       | 3500/12779 [00:03<00:09, 1013.63it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# tabfact\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bm25_with_title_results_tabfact_test \u001b[38;5;241m=\u001b[39m \u001b[43mrun_eval_for_top_ks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbm25_with_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbm25_with_title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtop_ks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tabfact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtabfact\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mrun_eval_for_top_ks\u001b[0;34m(retriever, retriever_name, top_ks, target, dataset_name, split)\u001b[0m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m top_k \u001b[38;5;129;01min\u001b[39;00m top_ks:\n\u001b[0;32m----> 4\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieval_results_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mretriever_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtop_k\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/carl/target/target_benchmark/evaluators/TARGET.py:513\u001b[0m, in \u001b[0;36mTARGET.run\u001b[0;34m(self, retriever, split, batch_size, top_k, retrieval_results_file, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         path_to_persistence\u001b[38;5;241m.\u001b[39mtouch()\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# run the task!\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m task_result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_loaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_to_persistence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_to_persistence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# add the embedding duration & sizes statistics to the results\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, results \u001b[38;5;129;01min\u001b[39;00m task_result\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/carl/target/target_benchmark/tasks/AbsTask.py:223\u001b[0m, in \u001b[0;36mAbsTask.task_run\u001b[0;34m(self, retriever, dataset_loaders, logger, batch_size, top_k, path_to_persistence, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[1;32m    220\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal_num_queries, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieving Tables for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m )\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_batch \u001b[38;5;129;01min\u001b[39;00m dataset_loader\u001b[38;5;241m.\u001b[39mget_queries_for_task(batch_size):\n\u001b[0;32m--> 223\u001b[0m     retrieved_tables, duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_retrieval_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_id_to_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     total_duration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m duration\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_retrieval_metrics(query_batch, retrieved_tables)\n",
      "File \u001b[0;32m~/carl/target/target_benchmark/tasks/AbsTask.py:342\u001b[0m, in \u001b[0;36mAbsTask._get_retrieval_results\u001b[0;34m(self, retriever, query_batch, table_id_to_table, dataset_name, top_k, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     retrieval_results \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39mretrieve_batch(\n\u001b[1;32m    336\u001b[0m         queries\u001b[38;5;241m=\u001b[39mquery_batch,\n\u001b[1;32m    337\u001b[0m         dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m    338\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    339\u001b[0m         client\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(CLIENT_KEY_NAME),\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(retriever, CustomEmbRetr):\n\u001b[0;32m--> 342\u001b[0m     retrieval_results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretriever passed in doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt inherit from the base retriever classes! (is of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(retriever)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m     )\n",
      "File \u001b[0;32m~/carl/target/target_benchmark/retrievers/AbsCustomEmbeddingRetriever.py:39\u001b[0m, in \u001b[0;36mAbsCustomEmbeddingRetriever.retrieve_batch\u001b[0;34m(self, queries, dataset_name, top_k, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m retrieval_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_id, query_str \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     33\u001b[0m     queries[QUERY_ID_COL_NAME], queries[QUERY_COL_NAME]\n\u001b[1;32m     34\u001b[0m ):\n\u001b[1;32m     35\u001b[0m     retrieval_results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     36\u001b[0m         RetrievalResultDataModel(\n\u001b[1;32m     37\u001b[0m             dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m     38\u001b[0m             query_id\u001b[38;5;241m=\u001b[39mquery_id,\n\u001b[0;32m---> 39\u001b[0m             retrieval_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retrieval_results\n",
      "File \u001b[0;32m~/carl/target/target_benchmark/retrievers/ottqa/OTTQARetriever.py:61\u001b[0m, in \u001b[0;36mOTTQARetriever.retrieve\u001b[0;34m(self, query, dataset_name, top_k, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     55\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     60\u001b[0m     ranker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrankers[dataset_name]\n\u001b[0;32m---> 61\u001b[0m     doc_names, doc_scores \u001b[38;5;241m=\u001b[39m \u001b[43mranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosest_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [ast\u001b[38;5;241m.\u001b[39mliteral_eval(doc_name) \u001b[38;5;28;01mfor\u001b[39;00m doc_name \u001b[38;5;129;01min\u001b[39;00m doc_names]\n",
      "File \u001b[0;32m~/carl/target/target_benchmark/retrievers/ottqa/drqa/retriever/BM25_doc_ranker.py:66\u001b[0m, in \u001b[0;36mBM25DocRanker.closest_docs\u001b[0;34m(self, query, k)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosest_docs\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Closest docs by dot product between query and documents\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    in tfidf weighted word vector space.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     spvec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext2spvec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     res \u001b[38;5;241m=\u001b[39m spvec \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_mat\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k:\n",
      "File \u001b[0;32m~/carl/target/target_benchmark/retrievers/ottqa/drqa/retriever/BM25_doc_ranker.py:110\u001b[0m, in \u001b[0;36mBM25DocRanker.text2spvec\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m sp\u001b[38;5;241m.\u001b[39mcsr_matrix((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhash_size))\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Count TF\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m wids_unique, wids_counts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m tfs \u001b[38;5;241m=\u001b[39m (wids_counts \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Count IDF\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/target/lib/python3.12/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/target/lib/python3.12/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tabfact\n",
    "bm25_with_title_results_tabfact_test = run_eval_for_top_ks(bm25_with_title, \"bm25_with_title\",top_ks, target_tabfact, \"tabfact\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.14719461616714924, precision=None, recall=None, retrieval_time=8.41716, avg_retrieval_time=0.00066), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.29053, avg_embedding_creation_duration=0.00253, embedding_size=0.49152, avg_embedding_size=0.00029))}},\n",
       " {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.27341732529931917, precision=None, recall=None, retrieval_time=9.53659, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.24604, avg_embedding_creation_duration=0.00251, embedding_size=0.0041, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.4433836763440019, precision=None, recall=None, retrieval_time=11.7532, avg_retrieval_time=0.00092), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.28083, avg_embedding_creation_duration=0.00253, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'tabfact': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.536818217387902, precision=None, recall=None, retrieval_time=15.02465, avg_retrieval_time=0.00118), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.28207, avg_embedding_creation_duration=0.00253, embedding_size=0.0041, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_with_title_results_tabfact_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ede19288bb54f5dae1fce6e8807df28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 132 files:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 592.16it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 195.55it/s]\n",
      "Retrieving Tables for spider-test...: 100%|██████████| 2147/2147 [00:08<00:00, 240.04it/s]\n",
      "1it [00:00, 474.68it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.27it/s]\n",
      "Retrieving Tables for spider-test...: 100%|██████████| 2147/2147 [00:23<00:00, 91.09it/s] \n",
      "1it [00:00, 221.56it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.56it/s]\n",
      "Retrieving Tables for spider-test...: 100%|██████████| 2147/2147 [00:28<00:00, 75.70it/s] \n",
      "1it [00:00, 512.81it/s]0:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 185.33it/s]\n",
      "Retrieving Tables for spider-test...: 100%|██████████| 2147/2147 [00:34<00:00, 62.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.6348393106660456, precision=None, recall=None, retrieval_time=1.82872, avg_retrieval_time=0.00085), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73522, avg_embedding_creation_duration=0.02075, embedding_size=-0.86016, avg_embedding_size=-0.00478))}}, {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.8304611085235212, precision=None, recall=None, retrieval_time=1.45708, avg_retrieval_time=0.00068), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.78847, avg_embedding_creation_duration=0.02105, embedding_size=0.0041, avg_embedding_size=2e-05))}}, {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.8737773637633908, precision=None, recall=None, retrieval_time=1.60808, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.75677, avg_embedding_creation_duration=0.02087, embedding_size=0.00819, avg_embedding_size=5e-05))}}, {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.8779692594317653, precision=None, recall=None, retrieval_time=1.7037, avg_retrieval_time=0.00079), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73507, avg_embedding_creation_duration=0.02075, embedding_size=0.0, avg_embedding_size=0.0))}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# spider\n",
    "bm25_with_title_results_spider_test = run_eval_for_top_ks(bm25_with_title, \"bm25_with_title\",top_ks, target_spider, \"spider\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.6348393106660456, precision=None, recall=None, retrieval_time=1.82872, avg_retrieval_time=0.00085), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73522, avg_embedding_creation_duration=0.02075, embedding_size=-0.86016, avg_embedding_size=-0.00478))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.8304611085235212, precision=None, recall=None, retrieval_time=1.45708, avg_retrieval_time=0.00068), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.78847, avg_embedding_creation_duration=0.02105, embedding_size=0.0041, avg_embedding_size=2e-05))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.8737773637633908, precision=None, recall=None, retrieval_time=1.60808, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.75677, avg_embedding_creation_duration=0.02087, embedding_size=0.00819, avg_embedding_size=5e-05))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.8779692594317653, precision=None, recall=None, retrieval_time=1.7037, avg_retrieval_time=0.00079), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73507, avg_embedding_creation_duration=0.02075, embedding_size=0.0, avg_embedding_size=0.0))}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_with_title_results_spider_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTTQA bm25 without Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_benchmark.retrievers import OTTQARetriever\n",
    "bm25_no_title = OTTQARetriever(encoding=\"bm25\", withtitle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 47.29it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.98it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:01<00:00, 1448.22it/s]\n",
      "1it [00:00, 46.31it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.00it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:01<00:00, 1229.51it/s]\n",
      "1it [00:00, 63.06it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.92it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:02<00:00, 902.35it/s]\n",
      "1it [00:00, 62.10it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.43it/s]\n",
      "Retrieving Tables for fetaqa...: 100%|██████████| 2003/2003 [00:02<00:00, 708.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.02895656515227159, precision=None, recall=None, retrieval_time=1.30831, avg_retrieval_time=0.00065), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.52735, avg_embedding_creation_duration=0.00226, embedding_size=0.00819, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.06090863704443335, precision=None, recall=None, retrieval_time=1.41867, avg_retrieval_time=0.00071), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.90114, avg_embedding_creation_duration=0.00245, embedding_size=0.0041, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.13030454318522217, precision=None, recall=None, retrieval_time=1.59272, avg_retrieval_time=0.0008), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.5114, avg_embedding_creation_duration=0.00225, embedding_size=0.00819, avg_embedding_size=0.0))}}, {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.18172740888667, precision=None, recall=None, retrieval_time=1.78035, avg_retrieval_time=0.00089), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.55346, avg_embedding_creation_duration=0.00227, embedding_size=0.0041, avg_embedding_size=0.0))}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fetaqa\n",
    "bm25_no_title_results_fetaqa_test = run_eval_for_top_ks(bm25_no_title, \"bm25_no_title\", top_ks, target_fetaqa, \"fetaqa\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.02895656515227159, precision=None, recall=None, retrieval_time=1.30831, avg_retrieval_time=0.00065), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.52735, avg_embedding_creation_duration=0.00226, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.06090863704443335, precision=None, recall=None, retrieval_time=1.41867, avg_retrieval_time=0.00071), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.90114, avg_embedding_creation_duration=0.00245, embedding_size=0.0041, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.13030454318522217, precision=None, recall=None, retrieval_time=1.59272, avg_retrieval_time=0.0008), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.5114, avg_embedding_creation_duration=0.00225, embedding_size=0.00819, avg_embedding_size=0.0))}},\n",
       " {'Table Retrieval Task': {'fetaqa': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.18172740888667, precision=None, recall=None, retrieval_time=1.78035, avg_retrieval_time=0.00089), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=4.55346, avg_embedding_creation_duration=0.00227, embedding_size=0.0041, avg_embedding_size=0.0))}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bm25_no_title_results_fetaqa_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ottqa\n",
    "bm25_no_title_results_ottqa_val = run_eval_for_top_ks(bm25_no_title, \"bm25_no_title\",top_ks, target_ottqa, \"ottqa\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_no_title_results_ottqa_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabfact\n",
    "bm25_no_title_results_tabfact_test = run_eval_for_top_ks(bm25_no_title, \"bm25_no_title\",top_ks, target_tabfact, \"tabfact\", \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_no_title_results_tabfact_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spider\n",
    "bm25_no_title_results_spider_test = run_eval_for_top_ks(bm25_no_title, \"bm25_no_title\",top_ks, target_spider, \"spider\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=1, accuracy=0.6348393106660456, precision=None, recall=None, retrieval_time=1.82872, avg_retrieval_time=0.00085), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73522, avg_embedding_creation_duration=0.02075, embedding_size=-0.86016, avg_embedding_size=-0.00478))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=5, accuracy=0.8304611085235212, precision=None, recall=None, retrieval_time=1.45708, avg_retrieval_time=0.00068), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.78847, avg_embedding_creation_duration=0.02105, embedding_size=0.0041, avg_embedding_size=2e-05))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=25, accuracy=0.8737773637633908, precision=None, recall=None, retrieval_time=1.60808, avg_retrieval_time=0.00075), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.75677, avg_embedding_creation_duration=0.02087, embedding_size=0.00819, avg_embedding_size=5e-05))}},\n",
       " {'Table Retrieval Task': {'spider-test': TaskResultsDataModel(retrieval_performance=RetrievalPerformanceDataModel(k=50, accuracy=0.8779692594317653, precision=None, recall=None, retrieval_time=1.7037, avg_retrieval_time=0.00079), downstream_task_performance=DownstreamTaskPerformanceDataModel(task_name=None, scores=None), embedding_statistics=EmbeddingStatisticsDataModel(embedding_creation_duration=3.73507, avg_embedding_creation_duration=0.02075, embedding_size=0.0, avg_embedding_size=0.0))}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bm25_no_title_results_spider_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "target",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
